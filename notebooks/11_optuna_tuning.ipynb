{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hyperparameter Tuning with Optuna\n",
                "\n",
                "## 1. Objective\n",
                "Our previous experiments showed that the Tree-based models (XGBoost, LightGBM, CatBoost) trained on 2D features are the strongest. To beat our best score (23.97), we will rigorously optimize their hyperparameters using **Optuna**.\n",
                "\n",
                "We will optimize for **MAE** (Mean Absolute Error) using 5-Fold Cross-Validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data Loaded: (2662, 2856)\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import optuna\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from catboost import CatBoostRegressor\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Set Optuna verbosity\n",
                "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
                "\n",
                "# Load Data\n",
                "train_df = pd.read_csv('../data/processed/train_featurized.csv')\n",
                "test_df = pd.read_csv('../data/processed/test_featurized.csv')\n",
                "\n",
                "X = train_df.drop(['id', 'SMILES', 'Tm'], axis=1)\n",
                "y = train_df['Tm']\n",
                "\n",
                "print(f\"Data Loaded: {X.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. XGBoost Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 08:43:34,598] A new study created in memory with name: no-name-d6534677-e6d9-4e19-b19a-ee5178b413cb\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tuning XGBoost...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 08:49:03,158] Trial 0 finished with value: 28.429271867383754 and parameters: {'learning_rate': 0.005647754396745869, 'max_depth': 4, 'subsample': 0.7901385077662257, 'colsample_bytree': 0.8588804383759647, 'reg_alpha': 0.0011873047061612607, 'reg_lambda': 3.1075229186109445, 'min_child_weight': 2}. Best is trial 0 with value: 28.429271867383754.\n",
                        "[I 2026-01-12 08:50:25,677] Trial 1 finished with value: 27.783555694913712 and parameters: {'learning_rate': 0.04575566639924989, 'max_depth': 7, 'subsample': 0.7264707081945254, 'colsample_bytree': 0.9704555057741865, 'reg_alpha': 0.019057750144696822, 'reg_lambda': 0.018098380182874522, 'min_child_weight': 8}. Best is trial 1 with value: 27.783555694913712.\n",
                        "[I 2026-01-12 08:55:37,689] Trial 2 finished with value: 28.073921502909748 and parameters: {'learning_rate': 0.005183970221330391, 'max_depth': 8, 'subsample': 0.9919805431799427, 'colsample_bytree': 0.8310736494844495, 'reg_alpha': 5.3021595462380455, 'reg_lambda': 0.005091047189961042, 'min_child_weight': 7}. Best is trial 1 with value: 27.783555694913712.\n",
                        "[I 2026-01-12 08:56:41,556] Trial 3 finished with value: 28.29422298116605 and parameters: {'learning_rate': 0.09049638746830882, 'max_depth': 4, 'subsample': 0.9850886244086593, 'colsample_bytree': 0.8802982060955903, 'reg_alpha': 4.730252249324736, 'reg_lambda': 0.014128740437955341, 'min_child_weight': 10}. Best is trial 1 with value: 27.783555694913712.\n",
                        "[I 2026-01-12 08:57:55,174] Trial 4 finished with value: 28.594951067612243 and parameters: {'learning_rate': 0.09201611854435135, 'max_depth': 9, 'subsample': 0.8854872518065962, 'colsample_bytree': 0.9179567461400393, 'reg_alpha': 0.954767258868279, 'reg_lambda': 0.2904683618839907, 'min_child_weight': 3}. Best is trial 1 with value: 27.783555694913712.\n",
                        "[I 2026-01-12 09:02:13,122] Trial 5 finished with value: 27.626822996448652 and parameters: {'learning_rate': 0.008151529570330197, 'max_depth': 7, 'subsample': 0.9553004644855978, 'colsample_bytree': 0.6078477547674864, 'reg_alpha': 6.603338212469008, 'reg_lambda': 0.024168341931435612, 'min_child_weight': 10}. Best is trial 5 with value: 27.626822996448652.\n",
                        "[I 2026-01-12 09:04:24,805] Trial 6 finished with value: 27.610994192394116 and parameters: {'learning_rate': 0.019627913255580585, 'max_depth': 5, 'subsample': 0.7675018477751288, 'colsample_bytree': 0.603693284972701, 'reg_alpha': 0.0015787213895146952, 'reg_lambda': 0.05657099259317442, 'min_child_weight': 7}. Best is trial 6 with value: 27.610994192394116.\n",
                        "[I 2026-01-12 09:08:19,635] Trial 7 finished with value: 27.789399036340683 and parameters: {'learning_rate': 0.012481859321840838, 'max_depth': 4, 'subsample': 0.7747491732466775, 'colsample_bytree': 0.7599964964900123, 'reg_alpha': 0.006303571038662559, 'reg_lambda': 0.015551923401623502, 'min_child_weight': 6}. Best is trial 6 with value: 27.610994192394116.\n",
                        "[I 2026-01-12 09:09:15,771] Trial 8 finished with value: 27.810269599520108 and parameters: {'learning_rate': 0.051233943946976286, 'max_depth': 6, 'subsample': 0.61799212265635, 'colsample_bytree': 0.9240923093394803, 'reg_alpha': 0.005980053692062959, 'reg_lambda': 0.054399705496374066, 'min_child_weight': 10}. Best is trial 6 with value: 27.610994192394116.\n",
                        "[I 2026-01-12 09:11:34,083] Trial 9 finished with value: 27.210163201031804 and parameters: {'learning_rate': 0.03369736996016932, 'max_depth': 5, 'subsample': 0.8252806518919187, 'colsample_bytree': 0.9124640399440078, 'reg_alpha': 0.006432932822825355, 'reg_lambda': 0.42357780509493115, 'min_child_weight': 3}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:15:45,019] Trial 10 finished with value: 28.409291241405743 and parameters: {'learning_rate': 0.029568820041387292, 'max_depth': 10, 'subsample': 0.8759799645210294, 'colsample_bytree': 0.756584095169624, 'reg_alpha': 0.1362017215083955, 'reg_lambda': 0.6623563632332538, 'min_child_weight': 4}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:21:05,649] Trial 11 finished with value: 27.237705321763446 and parameters: {'learning_rate': 0.01704522139001321, 'max_depth': 5, 'subsample': 0.668390016552445, 'colsample_bytree': 0.6353180828532645, 'reg_alpha': 0.0011129974980500952, 'reg_lambda': 0.1671738465827176, 'min_child_weight': 1}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:25:42,693] Trial 12 finished with value: 28.375106240467737 and parameters: {'learning_rate': 0.022949345376471128, 'max_depth': 3, 'subsample': 0.6596594314949408, 'colsample_bytree': 0.6842177878595341, 'reg_alpha': 0.06482962886350871, 'reg_lambda': 0.4275355870369179, 'min_child_weight': 1}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:30:57,050] Trial 13 finished with value: 27.362235114172517 and parameters: {'learning_rate': 0.0133991582236282, 'max_depth': 6, 'subsample': 0.686810254352372, 'colsample_bytree': 0.991474681030563, 'reg_alpha': 0.004343878787492896, 'reg_lambda': 7.8875592048429235, 'min_child_weight': 4}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:34:06,046] Trial 14 finished with value: 27.344118089864644 and parameters: {'learning_rate': 0.0365676492843367, 'max_depth': 5, 'subsample': 0.8505889351045764, 'colsample_bytree': 0.7161923852489952, 'reg_alpha': 0.02721110056547859, 'reg_lambda': 0.20425979429755883, 'min_child_weight': 1}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:38:33,906] Trial 15 finished with value: 27.39925019914432 and parameters: {'learning_rate': 0.01419416895883605, 'max_depth': 5, 'subsample': 0.6035975199820716, 'colsample_bytree': 0.7953721062534104, 'reg_alpha': 0.2678994167589317, 'reg_lambda': 1.2541157686676252, 'min_child_weight': 3}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:40:42,031] Trial 16 finished with value: 28.851528278057174 and parameters: {'learning_rate': 0.06207324003300552, 'max_depth': 3, 'subsample': 0.8473964924364825, 'colsample_bytree': 0.662097867310312, 'reg_alpha': 0.0024394932314534224, 'reg_lambda': 0.001168048231184669, 'min_child_weight': 2}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:43:55,516] Trial 17 finished with value: 27.28619782103317 and parameters: {'learning_rate': 0.023046926714766918, 'max_depth': 6, 'subsample': 0.7219627982671566, 'colsample_bytree': 0.9250299334916523, 'reg_alpha': 0.015905427297154887, 'reg_lambda': 0.123347006036329, 'min_child_weight': 5}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:49:02,285] Trial 18 finished with value: 27.92133731264151 and parameters: {'learning_rate': 0.009734152273965133, 'max_depth': 8, 'subsample': 0.9079621758538309, 'colsample_bytree': 0.7895737527118029, 'reg_alpha': 0.00102587062975547, 'reg_lambda': 2.0741596752437155, 'min_child_weight': 2}. Best is trial 9 with value: 27.210163201031804.\n",
                        "[I 2026-01-12 09:51:45,711] Trial 19 finished with value: 27.005419212238742 and parameters: {'learning_rate': 0.032149192305104574, 'max_depth': 5, 'subsample': 0.8182263532180157, 'colsample_bytree': 0.6438617477333907, 'reg_alpha': 0.011663247389322558, 'reg_lambda': 0.9180159830270932, 'min_child_weight': 1}. Best is trial 19 with value: 27.005419212238742.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best XGB Params: {'learning_rate': 0.032149192305104574, 'max_depth': 5, 'subsample': 0.8182263532180157, 'colsample_bytree': 0.6438617477333907, 'reg_alpha': 0.011663247389322558, 'reg_lambda': 0.9180159830270932, 'min_child_weight': 1}\n"
                    ]
                }
            ],
            "source": [
                "def objective_xgb(trial):\n",
                "    params = {\n",
                "        'n_estimators': 3000,\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
                "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
                "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
                "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
                "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
                "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
                "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
                "        'n_jobs': -1,\n",
                "        'random_state': 42,\n",
                "        'early_stopping_rounds': 100\n",
                "    }\n",
                "\n",
                "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "    mae_scores = []\n",
                "\n",
                "    for train_idx, val_idx in kf.split(X, y):\n",
                "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
                "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
                "\n",
                "        model = xgb.XGBRegressor(**params)\n",
                "        \n",
                "        # Fit with early stopping\n",
                "        model.fit(\n",
                "            X_train, y_train,\n",
                "            eval_set=[(X_val, y_val)],\n",
                "            verbose=False\n",
                "        )\n",
                "        \n",
                "        preds = model.predict(X_val)\n",
                "        mae_scores.append(mean_absolute_error(y_val, preds))\n",
                "\n",
                "    return np.mean(mae_scores)\n",
                "\n",
                "print(\"Tuning XGBoost...\")\n",
                "study_xgb = optuna.create_study(direction='minimize')\n",
                "study_xgb.optimize(objective_xgb, n_trials=20) # Running 20 trials for demonstration, increase for real run\n",
                "\n",
                "print(\"Best XGB Params:\", study_xgb.best_params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. LightGBM Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 09:51:45,728] A new study created in memory with name: no-name-0e85ed81-a2ca-44cd-bd72-d157c89cfa56\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tuning LightGBM...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 09:51:50,609] Trial 0 finished with value: 29.804475712302104 and parameters: {'learning_rate': 0.07792715728137667, 'num_leaves': 100, 'subsample': 0.7308420366559001, 'colsample_bytree': 0.793287680993924, 'reg_alpha': 0.0077265837915390595, 'reg_lambda': 0.0567537194418649, 'min_child_samples': 92}. Best is trial 0 with value: 29.804475712302104.\n",
                        "[I 2026-01-12 09:52:06,385] Trial 1 finished with value: 29.42913417264569 and parameters: {'learning_rate': 0.013094552320005587, 'num_leaves': 133, 'subsample': 0.8175064015940465, 'colsample_bytree': 0.7136212331609348, 'reg_alpha': 0.19023705831244916, 'reg_lambda': 0.1859263122277528, 'min_child_samples': 79}. Best is trial 1 with value: 29.42913417264569.\n",
                        "[I 2026-01-12 09:52:13,728] Trial 2 finished with value: 29.526610777268104 and parameters: {'learning_rate': 0.04063730025912167, 'num_leaves': 77, 'subsample': 0.6372510039798597, 'colsample_bytree': 0.8361164256668896, 'reg_alpha': 0.15853535462810997, 'reg_lambda': 1.8383716548217508, 'min_child_samples': 83}. Best is trial 1 with value: 29.42913417264569.\n",
                        "[I 2026-01-12 09:52:32,838] Trial 3 finished with value: 29.331921096497318 and parameters: {'learning_rate': 0.01917415124617669, 'num_leaves': 140, 'subsample': 0.9074807120746584, 'colsample_bytree': 0.870787398694524, 'reg_alpha': 0.3723433956512837, 'reg_lambda': 0.14323550532098137, 'min_child_samples': 45}. Best is trial 3 with value: 29.331921096497318.\n",
                        "[I 2026-01-12 09:52:47,621] Trial 4 finished with value: 29.635973343991616 and parameters: {'learning_rate': 0.02458783594169646, 'num_leaves': 118, 'subsample': 0.9993367971703796, 'colsample_bytree': 0.8035002743920335, 'reg_alpha': 0.38619621887359573, 'reg_lambda': 0.5486225009300916, 'min_child_samples': 64}. Best is trial 3 with value: 29.331921096497318.\n",
                        "[I 2026-01-12 09:52:57,265] Trial 5 finished with value: 29.20706587654439 and parameters: {'learning_rate': 0.06535645290251461, 'num_leaves': 87, 'subsample': 0.9055051126205825, 'colsample_bytree': 0.710114738039135, 'reg_alpha': 3.6531797250099807, 'reg_lambda': 0.017131115287396022, 'min_child_samples': 35}. Best is trial 5 with value: 29.20706587654439.\n",
                        "[I 2026-01-12 09:53:10,359] Trial 6 finished with value: 29.71816426449508 and parameters: {'learning_rate': 0.037146441270571706, 'num_leaves': 61, 'subsample': 0.9696659523288513, 'colsample_bytree': 0.9635396081552449, 'reg_alpha': 0.0369779925821788, 'reg_lambda': 0.41031354544550325, 'min_child_samples': 91}. Best is trial 5 with value: 29.20706587654439.\n",
                        "[I 2026-01-12 09:53:17,720] Trial 7 finished with value: 29.78180056078769 and parameters: {'learning_rate': 0.07168236113355103, 'num_leaves': 134, 'subsample': 0.6599136711099115, 'colsample_bytree': 0.7303702726380513, 'reg_alpha': 0.006912126073256411, 'reg_lambda': 0.016587282977179627, 'min_child_samples': 77}. Best is trial 5 with value: 29.20706587654439.\n",
                        "[I 2026-01-12 09:53:47,565] Trial 8 finished with value: 28.911515970229942 and parameters: {'learning_rate': 0.03458980941559351, 'num_leaves': 123, 'subsample': 0.9784853023509221, 'colsample_bytree': 0.9028056444176147, 'reg_alpha': 0.009222037606078278, 'reg_lambda': 0.008405249803033367, 'min_child_samples': 14}. Best is trial 8 with value: 28.911515970229942.\n",
                        "[I 2026-01-12 09:53:56,022] Trial 9 finished with value: 29.80811373920624 and parameters: {'learning_rate': 0.07101961100577073, 'num_leaves': 81, 'subsample': 0.9650541947469284, 'colsample_bytree': 0.8698238658053186, 'reg_alpha': 2.0659102803726808, 'reg_lambda': 0.0044109875557530355, 'min_child_samples': 73}. Best is trial 8 with value: 28.911515970229942.\n",
                        "[I 2026-01-12 09:55:57,498] Trial 10 finished with value: 27.718277706234936 and parameters: {'learning_rate': 0.0061542925659434, 'num_leaves': 42, 'subsample': 0.7977657473629396, 'colsample_bytree': 0.986324544510497, 'reg_alpha': 0.0013729235190525785, 'reg_lambda': 0.0012239639177871282, 'min_child_samples': 7}. Best is trial 10 with value: 27.718277706234936.\n",
                        "[I 2026-01-12 09:57:11,759] Trial 11 finished with value: 27.809008228194095 and parameters: {'learning_rate': 0.006221640147377706, 'num_leaves': 23, 'subsample': 0.8029294429125088, 'colsample_bytree': 0.9546506470561853, 'reg_alpha': 0.0012920481223100996, 'reg_lambda': 0.0013222353000112133, 'min_child_samples': 10}. Best is trial 10 with value: 27.718277706234936.\n",
                        "[I 2026-01-12 09:58:57,370] Trial 12 finished with value: 27.598228367231922 and parameters: {'learning_rate': 0.005183953242440183, 'num_leaves': 24, 'subsample': 0.7903499927266612, 'colsample_bytree': 0.9973376584690401, 'reg_alpha': 0.0012345956514182032, 'reg_lambda': 0.001159412963208994, 'min_child_samples': 5}. Best is trial 12 with value: 27.598228367231922.\n",
                        "[I 2026-01-12 09:59:54,931] Trial 13 finished with value: 28.62418946559571 and parameters: {'learning_rate': 0.005296482749460705, 'num_leaves': 20, 'subsample': 0.7283323132131767, 'colsample_bytree': 0.9961452236602332, 'reg_alpha': 0.001095286266669246, 'reg_lambda': 0.0011460384168978585, 'min_child_samples': 27}. Best is trial 12 with value: 27.598228367231922.\n",
                        "[I 2026-01-12 10:01:04,081] Trial 14 finished with value: 27.28613947485862 and parameters: {'learning_rate': 0.009885825629476801, 'num_leaves': 45, 'subsample': 0.8550205074388135, 'colsample_bytree': 0.6386218409676736, 'reg_alpha': 0.0044909797577605826, 'reg_lambda': 0.0031770350899868174, 'min_child_samples': 5}. Best is trial 14 with value: 27.28613947485862.\n",
                        "[I 2026-01-12 10:01:50,043] Trial 15 finished with value: 28.37971364225365 and parameters: {'learning_rate': 0.009973627173898365, 'num_leaves': 44, 'subsample': 0.8569147490909942, 'colsample_bytree': 0.6080293920616167, 'reg_alpha': 0.030154243159292222, 'reg_lambda': 9.867801982433752, 'min_child_samples': 24}. Best is trial 14 with value: 27.28613947485862.\n",
                        "[I 2026-01-12 10:02:25,844] Trial 16 finished with value: 29.119908873782343 and parameters: {'learning_rate': 0.009780076751748138, 'num_leaves': 43, 'subsample': 0.7486502583020632, 'colsample_bytree': 0.610868771699321, 'reg_alpha': 0.004823447019310073, 'reg_lambda': 0.0038562763027825716, 'min_child_samples': 51}. Best is trial 14 with value: 27.28613947485862.\n",
                        "[I 2026-01-12 10:03:07,006] Trial 17 finished with value: 28.433615657382045 and parameters: {'learning_rate': 0.008723789620026847, 'num_leaves': 53, 'subsample': 0.8775864769700134, 'colsample_bytree': 0.6609480570704775, 'reg_alpha': 0.02539033995501694, 'reg_lambda': 0.02841149684519598, 'min_child_samples': 21}. Best is trial 14 with value: 27.28613947485862.\n",
                        "[I 2026-01-12 10:03:27,410] Trial 18 finished with value: 28.948612331560064 and parameters: {'learning_rate': 0.014406530864320454, 'num_leaves': 33, 'subsample': 0.6903626068824937, 'colsample_bytree': 0.7576094941421734, 'reg_alpha': 0.0028691262985683463, 'reg_lambda': 0.0028219781128156077, 'min_child_samples': 35}. Best is trial 14 with value: 27.28613947485862.\n",
                        "[I 2026-01-12 10:04:58,447] Trial 19 finished with value: 27.789372578019112 and parameters: {'learning_rate': 0.00748678949200863, 'num_leaves': 64, 'subsample': 0.7687679528457755, 'colsample_bytree': 0.6530571299576831, 'reg_alpha': 0.017504253782401794, 'reg_lambda': 0.008075866275795346, 'min_child_samples': 5}. Best is trial 14 with value: 27.28613947485862.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best LightGBM Params: {'learning_rate': 0.009885825629476801, 'num_leaves': 45, 'subsample': 0.8550205074388135, 'colsample_bytree': 0.6386218409676736, 'reg_alpha': 0.0044909797577605826, 'reg_lambda': 0.0031770350899868174, 'min_child_samples': 5}\n"
                    ]
                }
            ],
            "source": [
                "def objective_lgb(trial):\n",
                "    params = {\n",
                "        'n_estimators': 3000,\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
                "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
                "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
                "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
                "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
                "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
                "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
                "        'n_jobs': -1,\n",
                "        'random_state': 42,\n",
                "        'verbosity': -1\n",
                "    }\n",
                "\n",
                "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "    mae_scores = []\n",
                "\n",
                "    for train_idx, val_idx in kf.split(X, y):\n",
                "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
                "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
                "\n",
                "        model = lgb.LGBMRegressor(**params)\n",
                "        \n",
                "        # LightGBM requires specific callbacks for early stopping in recent versions\n",
                "        callbacks = [lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
                "        \n",
                "        model.fit(\n",
                "            X_train, y_train,\n",
                "            eval_set=[(X_val, y_val)],\n",
                "            callbacks=callbacks\n",
                "        )\n",
                "        \n",
                "        preds = model.predict(X_val)\n",
                "        mae_scores.append(mean_absolute_error(y_val, preds))\n",
                "\n",
                "    return np.mean(mae_scores)\n",
                "\n",
                "print(\"Tuning LightGBM...\")\n",
                "study_lgb = optuna.create_study(direction='minimize')\n",
                "study_lgb.optimize(objective_lgb, n_trials=20)\n",
                "\n",
                "print(\"Best LightGBM Params:\", study_lgb.best_params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. CatBoost Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 10:04:58,470] A new study created in memory with name: no-name-3ad61783-f978-46b5-8ad4-8af2aed34c8b\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tuning CatBoost...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 10:10:51,877] Trial 0 finished with value: 27.09308222053185 and parameters: {'learning_rate': 0.0352337226770881, 'depth': 8, 'l2_leaf_reg': 7.68515693761527, 'random_strength': 9.679270622158992, 'bagging_temperature': 0.4743148262571497}. Best is trial 0 with value: 27.09308222053185.\n",
                        "[I 2026-01-12 10:13:08,979] Trial 1 finished with value: 29.922480957130375 and parameters: {'learning_rate': 0.008394403414311994, 'depth': 4, 'l2_leaf_reg': 4.075069765987971, 'random_strength': 3.5779950705963364, 'bagging_temperature': 0.5240983434273802}. Best is trial 0 with value: 27.09308222053185.\n",
                        "[I 2026-01-12 10:15:11,584] Trial 2 finished with value: 27.319745184561896 and parameters: {'learning_rate': 0.062344870892394696, 'depth': 6, 'l2_leaf_reg': 0.1181787488370042, 'random_strength': 3.6071505352094424, 'bagging_temperature': 0.012469266767700327}. Best is trial 0 with value: 27.09308222053185.\n",
                        "[I 2026-01-12 10:17:39,485] Trial 3 finished with value: 28.758612583220163 and parameters: {'learning_rate': 0.014822335963051611, 'depth': 4, 'l2_leaf_reg': 1.107264403148714, 'random_strength': 3.5240646721706033, 'bagging_temperature': 0.21789353950288926}. Best is trial 0 with value: 27.09308222053185.\n",
                        "[I 2026-01-12 10:22:11,570] Trial 4 finished with value: 27.07642927086173 and parameters: {'learning_rate': 0.03003877726196048, 'depth': 7, 'l2_leaf_reg': 0.0011734090789773254, 'random_strength': 6.973252263510745, 'bagging_temperature': 0.6099638142167177}. Best is trial 4 with value: 27.07642927086173.\n",
                        "[I 2026-01-12 10:26:59,699] Trial 5 finished with value: 27.772714440391503 and parameters: {'learning_rate': 0.06399417424830518, 'depth': 9, 'l2_leaf_reg': 0.0019660371686856795, 'random_strength': 6.982055453145911, 'bagging_temperature': 0.08520915431836351}. Best is trial 4 with value: 27.07642927086173.\n",
                        "[I 2026-01-12 10:32:47,830] Trial 6 finished with value: 27.05318792821395 and parameters: {'learning_rate': 0.03859044348158982, 'depth': 8, 'l2_leaf_reg': 0.8643903376115983, 'random_strength': 7.102351169364942, 'bagging_temperature': 0.10904200877579029}. Best is trial 6 with value: 27.05318792821395.\n",
                        "[I 2026-01-12 10:41:38,281] Trial 7 finished with value: 28.4525552163576 and parameters: {'learning_rate': 0.08059074093756703, 'depth': 10, 'l2_leaf_reg': 1.088451700504977, 'random_strength': 4.096532670621626, 'bagging_temperature': 0.8000781413544233}. Best is trial 6 with value: 27.05318792821395.\n",
                        "[I 2026-01-12 10:44:44,895] Trial 8 finished with value: 28.189397815371013 and parameters: {'learning_rate': 0.013721262813838798, 'depth': 5, 'l2_leaf_reg': 1.428269624496919, 'random_strength': 2.660895767770075, 'bagging_temperature': 0.7515292744890429}. Best is trial 6 with value: 27.05318792821395.\n",
                        "[I 2026-01-12 10:46:47,097] Trial 9 finished with value: 27.465572750524228 and parameters: {'learning_rate': 0.049537430550364386, 'depth': 5, 'l2_leaf_reg': 0.004335883883217147, 'random_strength': 3.791134404810334, 'bagging_temperature': 0.12204006148542179}. Best is trial 6 with value: 27.05318792821395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best CatBoost Params: {'learning_rate': 0.03859044348158982, 'depth': 8, 'l2_leaf_reg': 0.8643903376115983, 'random_strength': 7.102351169364942, 'bagging_temperature': 0.10904200877579029}\n"
                    ]
                }
            ],
            "source": [
                "def objective_cat(trial):\n",
                "    params = {\n",
                "        'iterations': 3000,\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
                "        'depth': trial.suggest_int('depth', 4, 10),\n",
                "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
                "        'random_strength': trial.suggest_float('random_strength', 1.0, 10.0),\n",
                "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
                "        'border_count': 254,\n",
                "        'verbose': False,\n",
                "        'random_state': 42,\n",
                "        'loss_function': 'MAE', # CatBoost can optimize MAE directly\n",
                "        'task_type': 'CPU'\n",
                "    }\n",
                "\n",
                "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "    mae_scores = []\n",
                "\n",
                "    for train_idx, val_idx in kf.split(X, y):\n",
                "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
                "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
                "\n",
                "        model = CatBoostRegressor(**params)\n",
                "        \n",
                "        model.fit(\n",
                "            X_train, y_train,\n",
                "            eval_set=[(X_val, y_val)],\n",
                "            early_stopping_rounds=100,\n",
                "            verbose=False\n",
                "        )\n",
                "        \n",
                "        preds = model.predict(X_val)\n",
                "        mae_scores.append(mean_absolute_error(y_val, preds))\n",
                "\n",
                "    return np.mean(mae_scores)\n",
                "\n",
                "print(\"Tuning CatBoost...\")\n",
                "study_cat = optuna.create_study(direction='minimize')\n",
                "study_cat.optimize(objective_cat, n_trials=10) # CatBoost is slower, fewer trials\n",
                "\n",
                "print(\"Best CatBoost Params:\", study_cat.best_params)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
