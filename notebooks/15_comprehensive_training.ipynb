{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# FINAL: Memory-Optimized Comprehensive Training\n",
                "\n",
                "## Optimizations Applied:\n",
                "1. **Batch Processing**: 5000 molecules at a time\n",
                "2. **Efficient dtypes**: float32/int8 instead of float64/int64\n",
                "3. **Reduced FP size**: Morgan 256 bits (from 512)\n",
                "4. **Garbage Collection**: Between batches"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from rdkit import Chem\n",
                "import lightgbm as lgb\n",
                "from lightgbm import LGBMRegressor\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "import sys\n",
                "import os\n",
                "import gc\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "from src.features import ComprehensiveFeaturizer\n",
                "\n",
                "def canonicalize(smiles):\n",
                "    try:\n",
                "        mol = Chem.MolFromSmiles(smiles)\n",
                "        if mol:\n",
                "            return Chem.MolToSmiles(mol, canonical=True)\n",
                "    except:\n",
                "        pass\n",
                "    return None\n",
                "\n",
                "print(\"Libraries loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load & Merge Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_train = pd.read_csv('../data/raw/train.csv')[['SMILES', 'Tm']]\n",
                "print(f\"Kaggle: {len(df_train)}\")\n",
                "\n",
                "try:\n",
                "    df_bradley = pd.read_excel('../data/raw/BradleyMeltingPointDataset.xlsx')\n",
                "    df_bradleyplus = pd.read_excel('../data/raw/BradleyDoublePlusGoodMeltingPointDataset.xlsx')\n",
                "    df_bradley['Tm'] = df_bradley['mpC'] + 273.15\n",
                "    df_bradleyplus['Tm'] = df_bradleyplus['mpC'] + 273.15\n",
                "    df_bradley = df_bradley[['smiles', 'Tm']].rename(columns={'smiles': 'SMILES'})\n",
                "    df_bradleyplus = df_bradleyplus[['smiles', 'Tm']].rename(columns={'smiles': 'SMILES'})\n",
                "    df_b_all = pd.concat([df_bradley, df_bradleyplus])\n",
                "    print(f\"Bradley: {len(df_b_all)}\")\n",
                "except Exception as e:\n",
                "    print(f\"Bradley: {e}\")\n",
                "    df_b_all = pd.DataFrame(columns=['SMILES', 'Tm'])\n",
                "\n",
                "try:\n",
                "    df_smiles_mp = pd.read_csv('../data/raw/smiles_melting_point.csv', on_bad_lines='skip')\n",
                "    df_smiles_mp = df_smiles_mp.rename(columns={'Melting Point {measured, converted}': 'Tm'})[['SMILES', 'Tm']]\n",
                "    print(f\"SMILES MP: {len(df_smiles_mp)}\")\n",
                "except Exception as e:\n",
                "    print(f\"SMILES MP: {e}\")\n",
                "    df_smiles_mp = pd.DataFrame(columns=['SMILES', 'Tm'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# External first, Kaggle last (so Kaggle labels take priority)\n",
                "full_train = pd.concat([df_smiles_mp, df_b_all, df_train], axis=0)\n",
                "print(f\"Combined: {len(full_train)}\")\n",
                "\n",
                "# Free memory\n",
                "del df_smiles_mp, df_b_all, df_bradley, df_bradleyplus, df_train\n",
                "gc.collect()\n",
                "\n",
                "print(\"Canonicalizing...\")\n",
                "full_train['SMILES'] = full_train['SMILES'].apply(canonicalize)\n",
                "full_train = full_train.dropna(subset=['SMILES'])\n",
                "full_train = full_train.drop_duplicates(subset=['SMILES'], keep='last')\n",
                "full_train = full_train.dropna(subset=['Tm']).reset_index(drop=True)\n",
                "\n",
                "print(f\"Final: {len(full_train)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Featurization (Batched)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use batch_size=5000 for memory efficiency\n",
                "featurizer = ComprehensiveFeaturizer(batch_size=5000)\n",
                "\n",
                "print(\"Featurizing Train...\")\n",
                "train_feats = featurizer.generate_features(full_train, smiles_col='SMILES')\n",
                "\n",
                "# Free memory\n",
                "del full_train\n",
                "gc.collect()\n",
                "\n",
                "print(f\"Train: {train_feats.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_raw = pd.read_csv('../data/raw/test.csv')\n",
                "print(\"Featurizing Test...\")\n",
                "test_feats = featurizer.generate_features(test_raw, smiles_col='SMILES')\n",
                "print(f\"Test: {test_feats.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare X, y\n",
                "non_feat = ['id', 'SMILES', 'Tm']\n",
                "feat_cols = [c for c in train_feats.columns if c not in non_feat]\n",
                "\n",
                "X = train_feats[feat_cols].copy()\n",
                "y = train_feats['Tm'].copy()\n",
                "\n",
                "# Align test\n",
                "for c in feat_cols:\n",
                "    if c not in test_feats.columns:\n",
                "        test_feats[c] = 0\n",
                "\n",
                "X_test = test_feats[feat_cols].copy()\n",
                "\n",
                "X = X.fillna(0)\n",
                "X_test = X_test.fillna(0)\n",
                "\n",
                "print(f\"X: {X.shape}, X_test: {X_test.shape}\")\n",
                "print(f\"Memory: X={X.memory_usage(deep=True).sum()/1024**2:.1f}MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train LightGBM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    'n_estimators': 2000,\n",
                "    'learning_rate': 0.1,\n",
                "    'num_leaves': 80,\n",
                "    'max_depth': 12,\n",
                "    'min_child_samples': 100,\n",
                "    'subsample': 0.8,\n",
                "    'colsample_bytree': 0.6,\n",
                "    'reg_alpha': 1.0,\n",
                "    'reg_lambda': 2.0,\n",
                "    'random_state': 42,\n",
                "    'verbose': -1,\n",
                "    'objective': 'regression_l1',\n",
                "    'metric': 'mae',\n",
                "    'n_jobs': -1\n",
                "}\n",
                "\n",
                "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "cv_scores = []\n",
                "test_preds = np.zeros(len(X_test))\n",
                "\n",
                "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
                "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
                "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
                "    \n",
                "    model = LGBMRegressor(**params)\n",
                "    model.fit(\n",
                "        X_tr, y_tr,\n",
                "        eval_set=[(X_val, y_val)],\n",
                "        callbacks=[lgb.early_stopping(100, verbose=False)]\n",
                "    )\n",
                "    \n",
                "    val_pred = model.predict(X_val)\n",
                "    mae = mean_absolute_error(y_val, val_pred)\n",
                "    cv_scores.append(mae)\n",
                "    print(f\"Fold {fold+1}: MAE={mae:.4f}\")\n",
                "    \n",
                "    test_preds += model.predict(X_test) / 5\n",
                "    \n",
                "    # Free memory between folds\n",
                "    del X_tr, X_val, y_tr, y_val\n",
                "    gc.collect()\n",
                "\n",
                "print(f\"\\n*** CV MAE: {np.mean(cv_scores):.4f} ***\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sub = pd.DataFrame({'id': test_raw['id'], 'Tm': test_preds})\n",
                "sub.to_csv('../submissions/submission_comprehensive_final.csv', index=False)\n",
                "print(\"Saved!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}