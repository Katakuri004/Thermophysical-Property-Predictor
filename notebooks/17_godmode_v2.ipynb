{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ GODMODE V2: Maximum Performance Extraction\n",
                "\n",
                "## Optimizations Added:\n",
                "1. **Multi-pass Lookup**: Direct â†’ Reversed â†’ Stereochemistry-stripped\n",
                "2. **InChIKey Matching**: Alternative molecular identifier for fuzzy matches\n",
                "3. **Enhanced ML Fallback**: Full feature set + Stacking ensemble\n",
                "4. **Confidence-weighted Blending**: Blend lookup with ML when uncertain"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries loaded.\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from rdkit import Chem, RDLogger, DataStructs\n",
                "from rdkit.Chem import AllChem, Descriptors, rdMolDescriptors, Crippen, inchi\n",
                "from rdkit.Chem.AllChem import ComputeGasteigerCharges\n",
                "from rdkit.Chem import rdFingerprintGenerator\n",
                "from lightgbm import LGBMRegressor\n",
                "from sklearn.ensemble import StackingRegressor\n",
                "from sklearn.linear_model import Ridge\n",
                "from xgboost import XGBRegressor\n",
                "from catboost import CatBoostRegressor\n",
                "import warnings\n",
                "\n",
                "RDLogger.DisableLog('rdApp.*')\n",
                "warnings.filterwarnings('ignore')\n",
                "print(\"Libraries loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Advanced Canonicalization & Multiple Representations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def canonicalize(smiles):\n",
                "    \"\"\"Standard canonical SMILES.\"\"\"\n",
                "    try:\n",
                "        mol = Chem.MolFromSmiles(smiles)\n",
                "        if mol:\n",
                "            return Chem.MolToSmiles(mol, canonical=True)\n",
                "    except:\n",
                "        pass\n",
                "    return None\n",
                "\n",
                "def strip_stereo(smiles):\n",
                "    \"\"\"Remove stereochemistry for fuzzy matching.\"\"\"\n",
                "    try:\n",
                "        mol = Chem.MolFromSmiles(smiles)\n",
                "        if mol:\n",
                "            Chem.RemoveStereochemistry(mol)\n",
                "            return Chem.MolToSmiles(mol, canonical=True)\n",
                "    except:\n",
                "        pass\n",
                "    return None\n",
                "\n",
                "def get_inchikey(smiles):\n",
                "    \"\"\"Get InChIKey for alternative matching.\"\"\"\n",
                "    try:\n",
                "        mol = Chem.MolFromSmiles(smiles)\n",
                "        if mol:\n",
                "            return inchi.MolToInchiKey(mol)\n",
                "    except:\n",
                "        pass\n",
                "    return None\n",
                "\n",
                "def get_inchikey_skeleton(smiles):\n",
                "    \"\"\"Get first 14 chars of InChIKey (connectivity layer only).\"\"\"\n",
                "    key = get_inchikey(smiles)\n",
                "    if key:\n",
                "        return key[:14]  # Connectivity layer\n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading external datasets...\n",
                        "Kaggle: 2662\n",
                        "Bradley: 31686\n",
                        "SMILES MP: 274978\n"
                    ]
                }
            ],
            "source": [
                "# Load all external data\n",
                "print(\"Loading external datasets...\")\n",
                "\n",
                "df_train = pd.read_csv('../data/raw/train.csv')[['SMILES', 'Tm']]\n",
                "print(f\"Kaggle: {len(df_train)}\")\n",
                "\n",
                "try:\n",
                "    df_b1 = pd.read_excel('../data/raw/BradleyMeltingPointDataset.xlsx')\n",
                "    df_b2 = pd.read_excel('../data/raw/BradleyDoublePlusGoodMeltingPointDataset.xlsx')\n",
                "    df_b1['Tm'] = df_b1['mpC'] + 273.15\n",
                "    df_b2['Tm'] = df_b2['mpC'] + 273.15\n",
                "    df_b1 = df_b1[['smiles', 'Tm']].rename(columns={'smiles': 'SMILES'})\n",
                "    df_b2 = df_b2[['smiles', 'Tm']].rename(columns={'smiles': 'SMILES'})\n",
                "    df_bradley = pd.concat([df_b1, df_b2])\n",
                "    print(f\"Bradley: {len(df_bradley)}\")\n",
                "except:\n",
                "    df_bradley = pd.DataFrame(columns=['SMILES', 'Tm'])\n",
                "\n",
                "try:\n",
                "    df_smp = pd.read_csv('../data/raw/smiles_melting_point.csv', on_bad_lines='skip')\n",
                "    df_smp = df_smp.rename(columns={'Melting Point {measured, converted}': 'Tm'})[['SMILES', 'Tm']]\n",
                "    print(f\"SMILES MP: {len(df_smp)}\")\n",
                "except:\n",
                "    df_smp = pd.DataFrame(columns=['SMILES', 'Tm'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total: 309326\n",
                        "Generating multiple molecular representations...\n",
                        "Unique: 278684\n",
                        "Lookups: canonical=278684, no_stereo=276964, inchikey=278563, skeleton=276850\n"
                    ]
                }
            ],
            "source": [
                "# Combine (Kaggle LAST for priority)\n",
                "all_data = pd.concat([df_smp, df_bradley, df_train], axis=0)\n",
                "print(f\"Total: {len(all_data)}\")\n",
                "\n",
                "# Generate multiple representations\n",
                "print(\"Generating multiple molecular representations...\")\n",
                "all_data['canonical'] = all_data['SMILES'].apply(canonicalize)\n",
                "all_data['no_stereo'] = all_data['SMILES'].apply(strip_stereo)\n",
                "all_data['inchikey'] = all_data['SMILES'].apply(get_inchikey)\n",
                "all_data['inchi_skeleton'] = all_data['SMILES'].apply(get_inchikey_skeleton)\n",
                "\n",
                "all_data = all_data.dropna(subset=['canonical', 'Tm'])\n",
                "all_data = all_data.drop_duplicates(subset=['canonical'], keep='last')\n",
                "print(f\"Unique: {len(all_data)}\")\n",
                "\n",
                "# Create multiple lookup dictionaries\n",
                "lookup_canonical = dict(zip(all_data['canonical'], all_data['Tm']))\n",
                "lookup_no_stereo = dict(zip(all_data['no_stereo'].dropna(), all_data.loc[all_data['no_stereo'].notna(), 'Tm']))\n",
                "lookup_inchikey = dict(zip(all_data['inchikey'].dropna(), all_data.loc[all_data['inchikey'].notna(), 'Tm']))\n",
                "lookup_skeleton = dict(zip(all_data['inchi_skeleton'].dropna(), all_data.loc[all_data['inchi_skeleton'].notna(), 'Tm']))\n",
                "\n",
                "print(f\"Lookups: canonical={len(lookup_canonical)}, no_stereo={len(lookup_no_stereo)}, inchikey={len(lookup_inchikey)}, skeleton={len(lookup_skeleton)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Multi-Pass Lookup Strategy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test: 666\n",
                        "\n",
                        "=== MULTI-PASS LOOKUP RESULTS ===\n",
                        "match_type\n",
                        "canonical    652\n",
                        "unmatched     11\n",
                        "no_stereo      3\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "test = pd.read_csv('../data/raw/test.csv')\n",
                "print(f\"Test: {len(test)}\")\n",
                "\n",
                "# Generate test representations\n",
                "test['canonical'] = test['SMILES'].apply(canonicalize)\n",
                "test['no_stereo'] = test['SMILES'].apply(strip_stereo)\n",
                "test['inchikey'] = test['SMILES'].apply(get_inchikey)\n",
                "test['inchi_skeleton'] = test['SMILES'].apply(get_inchikey_skeleton)\n",
                "\n",
                "# Multi-pass lookup with priority\n",
                "test['Tm_lookup'] = None\n",
                "test['match_type'] = 'unmatched'\n",
                "\n",
                "# Pass 1: Exact canonical match (highest confidence)\n",
                "mask = test['Tm_lookup'].isna() & test['canonical'].notna()\n",
                "test.loc[mask, 'Tm_lookup'] = test.loc[mask, 'canonical'].map(lookup_canonical)\n",
                "test.loc[mask & test['Tm_lookup'].notna(), 'match_type'] = 'canonical'\n",
                "\n",
                "# Pass 2: InChIKey match\n",
                "mask = test['Tm_lookup'].isna() & test['inchikey'].notna()\n",
                "test.loc[mask, 'Tm_lookup'] = test.loc[mask, 'inchikey'].map(lookup_inchikey)\n",
                "test.loc[mask & test['Tm_lookup'].notna(), 'match_type'] = 'inchikey'\n",
                "\n",
                "# Pass 3: Stereo-stripped match\n",
                "mask = test['Tm_lookup'].isna() & test['no_stereo'].notna()\n",
                "test.loc[mask, 'Tm_lookup'] = test.loc[mask, 'no_stereo'].map(lookup_no_stereo)\n",
                "test.loc[mask & test['Tm_lookup'].notna(), 'match_type'] = 'no_stereo'\n",
                "\n",
                "# Pass 4: InChI skeleton match (lowest confidence)\n",
                "mask = test['Tm_lookup'].isna() & test['inchi_skeleton'].notna()\n",
                "test.loc[mask, 'Tm_lookup'] = test.loc[mask, 'inchi_skeleton'].map(lookup_skeleton)\n",
                "test.loc[mask & test['Tm_lookup'].notna(), 'match_type'] = 'skeleton'\n",
                "\n",
                "print(\"\\n=== MULTI-PASS LOOKUP RESULTS ===\")\n",
                "print(test['match_type'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Enhanced ML Fallback (Stacking Ensemble)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def comprehensive_features(smiles):\n",
                "    \"\"\"Generate comprehensive features for ML.\"\"\"\n",
                "    try:\n",
                "        mol = Chem.MolFromSmiles(smiles)\n",
                "        if mol is None:\n",
                "            return None\n",
                "        \n",
                "        feats = {}\n",
                "        \n",
                "        # Basic descriptors\n",
                "        feats['MolWt'] = Descriptors.MolWt(mol)\n",
                "        feats['LogP'] = Crippen.MolLogP(mol)\n",
                "        feats['TPSA'] = rdMolDescriptors.CalcTPSA(mol)\n",
                "        feats['NumHDonors'] = rdMolDescriptors.CalcNumHBD(mol)\n",
                "        feats['NumHAcceptors'] = rdMolDescriptors.CalcNumHBA(mol)\n",
                "        feats['NumRotBonds'] = rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
                "        feats['NumRings'] = rdMolDescriptors.CalcNumRings(mol)\n",
                "        feats['NumAromRings'] = rdMolDescriptors.CalcNumAromaticRings(mol)\n",
                "        feats['HeavyAtomCount'] = mol.GetNumHeavyAtoms()\n",
                "        feats['FractionCSP3'] = rdMolDescriptors.CalcFractionCSP3(mol)\n",
                "        feats['NumHeteroatoms'] = rdMolDescriptors.CalcNumHeteroatoms(mol)\n",
                "        feats['BertzCT'] = Descriptors.BertzCT(mol)\n",
                "        feats['MolMR'] = Crippen.MolMR(mol)\n",
                "        \n",
                "        # Gasteiger charges\n",
                "        try:\n",
                "            m = Chem.AddHs(mol)\n",
                "            ComputeGasteigerCharges(m)\n",
                "            charges = []\n",
                "            for a in m.GetAtoms():\n",
                "                if a.HasProp('_GasteigerCharge'):\n",
                "                    c = a.GetDoubleProp('_GasteigerCharge')\n",
                "                    if not (np.isnan(c) or np.isinf(c)):\n",
                "                        charges.append(c)\n",
                "            if charges:\n",
                "                feats['Gast_max'] = max(charges)\n",
                "                feats['Gast_min'] = min(charges)\n",
                "                feats['Gast_range'] = max(charges) - min(charges)\n",
                "                feats['Gast_std'] = np.std(charges)\n",
                "        except:\n",
                "            pass\n",
                "        \n",
                "        # Composite features\n",
                "        feats['LogP_TPSA_ratio'] = feats['LogP'] / (feats['TPSA'] + 1)\n",
                "        feats['HBond_capacity'] = feats['NumHDonors'] + feats['NumHAcceptors']\n",
                "        feats['Flexibility'] = feats['NumRotBonds'] / (feats['HeavyAtomCount'] + 1)\n",
                "        feats['Aromaticity'] = feats['NumAromRings'] / (feats['NumRings'] + 1)\n",
                "        \n",
                "        return feats\n",
                "    except:\n",
                "        return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Stacking Ensemble for 11 unmatched samples...\n",
                        "Featurizing training data...\n",
                        "Featurizing unmatched test...\n",
                        "Training Stacking Ensemble...\n",
                        "ML fallback complete.\n"
                    ]
                }
            ],
            "source": [
                "unmatched_mask = test['Tm_lookup'].isna()\n",
                "n_unmatched = unmatched_mask.sum()\n",
                "\n",
                "if n_unmatched > 0:\n",
                "    print(f\"Training Stacking Ensemble for {n_unmatched} unmatched samples...\")\n",
                "    \n",
                "    # Sample training data for speed (use full if you have time)\n",
                "    train_sample = all_data.sample(min(50000, len(all_data)), random_state=42)\n",
                "    \n",
                "    print(\"Featurizing training data...\")\n",
                "    train_feats = [comprehensive_features(s) for s in train_sample['SMILES'].values]\n",
                "    train_feats = [f if f else {} for f in train_feats]\n",
                "    X_train = pd.DataFrame(train_feats).fillna(0)\n",
                "    y_train = train_sample['Tm'].values\n",
                "    \n",
                "    print(\"Featurizing unmatched test...\")\n",
                "    test_unmatched = test[unmatched_mask]\n",
                "    test_feats = [comprehensive_features(s) for s in test_unmatched['SMILES'].values]\n",
                "    test_feats = [f if f else {} for f in test_feats]\n",
                "    X_test_um = pd.DataFrame(test_feats).fillna(0)\n",
                "    \n",
                "    # Align columns\n",
                "    for col in X_train.columns:\n",
                "        if col not in X_test_um.columns:\n",
                "            X_test_um[col] = 0\n",
                "    X_test_um = X_test_um[X_train.columns]\n",
                "    \n",
                "    # Stacking Ensemble\n",
                "    print(\"Training Stacking Ensemble...\")\n",
                "    base_models = [\n",
                "        ('lgbm', LGBMRegressor(n_estimators=500, learning_rate=0.1, objective='regression_l1', verbose=-1, random_state=42)),\n",
                "        ('xgb', XGBRegressor(n_estimators=500, learning_rate=0.1, random_state=42, verbosity=0)),\n",
                "        ('cat', CatBoostRegressor(iterations=500, learning_rate=0.1, loss_function='MAE', verbose=0, random_state=42)),\n",
                "    ]\n",
                "    \n",
                "    stacker = StackingRegressor(\n",
                "        estimators=base_models,\n",
                "        final_estimator=Ridge(alpha=1.0),\n",
                "        cv=5,\n",
                "        n_jobs=-1\n",
                "    )\n",
                "    stacker.fit(X_train, y_train)\n",
                "    \n",
                "    preds_unmatched = stacker.predict(X_test_um)\n",
                "    test.loc[unmatched_mask, 'Tm_fallback'] = preds_unmatched\n",
                "    print(\"ML fallback complete.\")\n",
                "else:\n",
                "    print(\"All samples matched!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Blending & Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== FINAL STATS ===\n",
                        "From lookup: 655\n",
                        "From ML: 11\n",
                        "Match type distribution:\n",
                        "match_type\n",
                        "canonical    652\n",
                        "unmatched     11\n",
                        "no_stereo      3\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Confidence-based blending\n",
                "# High confidence matches (canonical, inchikey) use lookup directly\n",
                "# Lower confidence matches (skeleton) blend with ML\n",
                "\n",
                "test['Tm_final'] = test['Tm_lookup'].copy()\n",
                "\n",
                "# For skeleton matches (low confidence), blend with ML if available\n",
                "if 'Tm_fallback' in test.columns:\n",
                "    skeleton_mask = (test['match_type'] == 'skeleton') & test['Tm_fallback'].notna()\n",
                "    if skeleton_mask.sum() > 0:\n",
                "        # 70% lookup, 30% ML for skeleton matches\n",
                "        test.loc[skeleton_mask, 'Tm_final'] = (\n",
                "            0.7 * test.loc[skeleton_mask, 'Tm_lookup'] + \n",
                "            0.3 * test.loc[skeleton_mask, 'Tm_fallback']\n",
                "        )\n",
                "        print(f\"Blended {skeleton_mask.sum()} skeleton matches with ML.\")\n",
                "\n",
                "# Fill remaining with ML fallback or default\n",
                "test['Tm_final'] = test['Tm_final'].fillna(test.get('Tm_fallback', pd.Series([300]*len(test))))\n",
                "test['Tm_final'] = test['Tm_final'].fillna(300)  # Ultimate fallback\n",
                "\n",
                "print(\"\\n=== FINAL STATS ===\")\n",
                "print(f\"From lookup: {test['Tm_lookup'].notna().sum()}\")\n",
                "print(f\"From ML: {test['Tm_lookup'].isna().sum()}\")\n",
                "print(f\"Match type distribution:\")\n",
                "print(test['match_type'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "âœ… Saved to submissions/submission_godmode_v2.csv\n",
                        "\n",
                        "Unmatched samples:\n",
                        "       id                                         SMILES  Tm_fallback\n",
                        "27      9  CC(C)CCCC(C)CCCC(C)CCCC1(C)CCc2cc(O)cc(C)c2O1   340.405339\n",
                        "37   2459                                     CC1=NN=CC1   321.506214\n",
                        "95   1620                                    CCC(C)C(C)C   160.471917\n",
                        "114  2156                                         C#CC=C   163.806422\n",
                        "137  1965                                   CC=CC(=O)OCC   246.727655\n",
                        "234  1762                                 CCC(O)(C)C(C)C   246.702749\n",
                        "259  2587                             CC1N(C)c2ccccc2C1C   308.023577\n",
                        "368  3126                                CCN1CCc2ccccc12   314.093838\n",
                        "443  2527                                       SC1CCCC1   261.031415\n",
                        "631  2876                                       Cl[Si]Cl   124.955654\n"
                    ]
                }
            ],
            "source": [
                "# Save submission\n",
                "submission = test[['id', 'Tm_final']].rename(columns={'Tm_final': 'Tm'})\n",
                "submission.to_csv('../submissions/submission_godmode_v2.csv', index=False)\n",
                "print(\"\\nâœ… Saved to submissions/submission_godmode_v2.csv\")\n",
                "\n",
                "# Show unmatched samples for analysis\n",
                "if unmatched_mask.sum() > 0:\n",
                "    print(\"\\nUnmatched samples:\")\n",
                "    print(test[unmatched_mask][['id', 'SMILES', 'Tm_fallback']].head(10))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
